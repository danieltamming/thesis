  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:55<05:47, 115.88s/it] 50%|█████     | 2/4 [03:49<03:50, 115.28s/it] 75%|███████▌  | 3/4 [05:43<01:54, 114.94s/it]100%|██████████| 4/4 [07:37<00:00, 114.64s/it]100%|██████████| 4/4 [07:37<00:00, 114.46s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:14<00:42, 14.21s/it] 50%|█████     | 2/4 [00:28<00:28, 14.13s/it] 75%|███████▌  | 3/4 [00:41<00:14, 14.01s/it]100%|██████████| 4/4 [00:55<00:00, 13.91s/it]100%|██████████| 4/4 [00:55<00:00, 13.90s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [02:47<08:23, 167.94s/it] 50%|█████     | 2/4 [05:28<05:31, 165.75s/it] 75%|███████▌  | 3/4 [08:10<02:44, 164.64s/it]100%|██████████| 4/4 [10:52<00:00, 163.93s/it]100%|██████████| 4/4 [10:52<00:00, 163.23s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [02:36<07:49, 156.51s/it] 50%|█████     | 2/4 [05:11<05:11, 155.94s/it] 75%|███████▌  | 3/4 [07:43<02:34, 154.93s/it]100%|██████████| 4/4 [10:16<00:00, 154.40s/it]100%|██████████| 4/4 [10:16<00:00, 154.21s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [02:25<07:15, 145.22s/it] 50%|█████     | 2/4 [04:48<04:48, 144.49s/it] 75%|███████▌  | 3/4 [07:09<02:23, 143.70s/it]100%|██████████| 4/4 [09:28<00:00, 142.10s/it]100%|██████████| 4/4 [09:28<00:00, 142.05s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [02:12<06:38, 132.95s/it] 50%|█████     | 2/4 [04:23<04:24, 132.25s/it] 75%|███████▌  | 3/4 [06:34<02:11, 131.92s/it]100%|██████████| 4/4 [08:46<00:00, 132.00s/it]100%|██████████| 4/4 [08:46<00:00, 131.72s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [02:04<06:13, 124.65s/it] 50%|█████     | 2/4 [04:07<04:08, 124.14s/it] 75%|███████▌  | 3/4 [06:08<02:03, 123.13s/it]100%|██████████| 4/4 [08:08<00:00, 122.37s/it]100%|██████████| 4/4 [08:08<00:00, 122.25s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:49<05:27, 109.25s/it] 50%|█████     | 2/4 [03:37<03:37, 108.83s/it] 75%|███████▌  | 3/4 [05:24<01:48, 108.50s/it]100%|██████████| 4/4 [07:12<00:00, 108.19s/it]100%|██████████| 4/4 [07:12<00:00, 108.08s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:13<00:40, 13.52s/it] 50%|█████     | 2/4 [00:26<00:26, 13.46s/it] 75%|███████▌  | 3/4 [00:40<00:13, 13.37s/it]100%|██████████| 4/4 [00:53<00:00, 13.29s/it]100%|██████████| 4/4 [00:53<00:00, 13.27s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [02:46<08:18, 166.19s/it] 50%|█████     | 2/4 [05:23<05:27, 163.59s/it] 75%|███████▌  | 3/4 [07:58<02:40, 160.84s/it]100%|██████████| 4/4 [10:31<00:00, 158.73s/it]100%|██████████| 4/4 [10:31<00:00, 157.98s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [02:24<07:12, 144.01s/it] 50%|█████     | 2/4 [04:48<04:48, 144.23s/it] 75%|███████▌  | 3/4 [07:11<02:23, 143.77s/it]100%|██████████| 4/4 [09:35<00:00, 143.75s/it]100%|██████████| 4/4 [09:35<00:00, 143.79s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [02:15<06:45, 135.04s/it] 50%|█████     | 2/4 [04:29<04:29, 134.88s/it] 75%|███████▌  | 3/4 [06:43<02:14, 134.70s/it]100%|██████████| 4/4 [08:58<00:00, 134.68s/it]100%|██████████| 4/4 [08:58<00:00, 134.62s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [02:06<06:18, 126.26s/it] 50%|█████     | 2/4 [04:11<04:11, 125.83s/it] 75%|███████▌  | 3/4 [06:15<02:05, 125.26s/it]100%|██████████| 4/4 [08:18<00:00, 124.85s/it]100%|██████████| 4/4 [08:18<00:00, 124.73s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:56<05:49, 116.47s/it] 50%|█████     | 2/4 [03:51<03:52, 116.02s/it] 75%|███████▌  | 3/4 [05:46<01:55, 115.67s/it]100%|██████████| 4/4 [07:40<00:00, 115.28s/it]100%|██████████| 4/4 [07:40<00:00, 115.17s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:46<05:20, 106.99s/it] 50%|█████     | 2/4 [03:32<03:32, 106.46s/it] 75%|███████▌  | 3/4 [05:17<01:45, 105.99s/it]100%|██████████| 4/4 [07:02<00:00, 105.66s/it]100%|██████████| 4/4 [07:02<00:00, 105.50s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:23<01:11, 23.67s/it] 50%|█████     | 2/4 [00:46<00:47, 23.55s/it] 75%|███████▌  | 3/4 [01:10<00:23, 23.42s/it]100%|██████████| 4/4 [01:33<00:00, 23.28s/it]100%|██████████| 4/4 [01:33<00:00, 23.25s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [02:33<07:41, 153.96s/it] 50%|█████     | 2/4 [05:07<05:07, 153.92s/it] 75%|███████▌  | 3/4 [07:45<02:34, 154.97s/it]100%|██████████| 4/4 [10:22<00:00, 155.66s/it]100%|██████████| 4/4 [10:22<00:00, 155.61s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [02:21<07:05, 141.88s/it] 50%|█████     | 2/4 [04:41<04:42, 141.33s/it] 75%|███████▌  | 3/4 [07:02<02:21, 141.21s/it]100%|██████████| 4/4 [09:25<00:00, 141.55s/it]100%|██████████| 4/4 [09:25<00:00, 141.30s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [02:13<06:41, 133.92s/it] 50%|█████     | 2/4 [04:26<04:26, 133.49s/it] 75%|███████▌  | 3/4 [06:37<02:12, 132.89s/it]100%|██████████| 4/4 [08:50<00:00, 132.78s/it]100%|██████████| 4/4 [08:50<00:00, 132.61s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [02:05<06:17, 125.97s/it] 50%|█████     | 2/4 [04:09<04:10, 125.21s/it] 75%|███████▌  | 3/4 [06:13<02:04, 124.91s/it]100%|██████████| 4/4 [08:17<00:00, 124.62s/it]100%|██████████| 4/4 [08:17<00:00, 124.39s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:55<05:47, 115.89s/it] 50%|█████     | 2/4 [03:50<03:51, 115.58s/it] 75%|███████▌  | 3/4 [05:45<01:55, 115.34s/it]100%|██████████| 4/4 [07:39<00:00, 115.07s/it]100%|██████████| 4/4 [07:39<00:00, 114.99s/it]
  0%|          | 0/4 [00:00<?, ?it/s]  0%|          | 0/4 [00:00<?, ?it/s]
Model is Bert, dataset is subj, undersample is False, aug mode is None, geo is 0.5, small_label is 0, small_prop is 0.1, balance_seed is 0
4500 4500
4500 450
4500 4500
Training epoch 0 | loss: 0.20169 - accuracy: 0.92411
Validating epoch 0 | loss: 0.58137 - accuracy: 0.909
115.879 s/it
Training epoch 1 | loss: 0.02098 - accuracy: 0.99611
Validating epoch 1 | loss: 1.30753 - accuracy: 0.822
Training epoch 2 | loss: 0.00396 - accuracy: 0.99922
Validating epoch 2 | loss: 1.93875 - accuracy: 0.789
Training epoch 3 | loss: 0.00124 - accuracy: 0.99978
Validating epoch 3 | loss: 1.60317 - accuracy: 0.828
Model is Bert, dataset is subj, undersample is True, aug mode is None, geo is 0.5, small_label is 0, small_prop is 0.1, balance_seed is 0
4500 4500
4500 450
450 450
Training epoch 0 | loss: 0.39367 - accuracy: 0.82667
Validating epoch 0 | loss: 0.3672 - accuracy: 0.894
14.206 s/it
Training epoch 1 | loss: 0.18601 - accuracy: 0.95
Validating epoch 1 | loss: 0.29378 - accuracy: 0.929
Training epoch 2 | loss: 0.03316 - accuracy: 0.99222
Validating epoch 2 | loss: 0.42049 - accuracy: 0.922
Training epoch 3 | loss: 0.01617 - accuracy: 0.99556
Validating epoch 3 | loss: 0.3748 - accuracy: 0.929
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.5, small_label is 0, small_prop is 0.1, balance_seed is 0
4500 4500
4500 450
4500 4500
Training epoch 0 | loss: 0.19154 - accuracy: 0.93422
Validating epoch 0 | loss: 0.70159 - accuracy: 0.883
167.936 s/it
Training epoch 1 | loss: 0.02828 - accuracy: 0.99411
Validating epoch 1 | loss: 0.66957 - accuracy: 0.912
Training epoch 2 | loss: 0.00456 - accuracy: 0.99911
Validating epoch 2 | loss: 1.52194 - accuracy: 0.819
Training epoch 3 | loss: 0.00274 - accuracy: 0.99967
Validating epoch 3 | loss: 1.26393 - accuracy: 0.846
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.6, small_label is 0, small_prop is 0.1, balance_seed is 0
4500 4500
4500 450
4500 4500
Training epoch 0 | loss: 0.19509 - accuracy: 0.92856
Validating epoch 0 | loss: 0.43804 - accuracy: 0.931
156.508 s/it
Training epoch 1 | loss: 0.02856 - accuracy: 0.99456
Validating epoch 1 | loss: 1.64151 - accuracy: 0.784
Training epoch 2 | loss: 0.00622 - accuracy: 0.999
Validating epoch 2 | loss: 1.41037 - accuracy: 0.844
Training epoch 3 | loss: 0.00122 - accuracy: 0.99978
Validating epoch 3 | loss: 1.33353 - accuracy: 0.857
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.7, small_label is 0, small_prop is 0.1, balance_seed is 0
4500 4500
4500 450
4500 4500
Training epoch 0 | loss: 0.17873 - accuracy: 0.94078
Validating epoch 0 | loss: 0.58543 - accuracy: 0.907
145.225 s/it
Training epoch 1 | loss: 0.02784 - accuracy: 0.99489
Validating epoch 1 | loss: 1.33015 - accuracy: 0.826
Training epoch 2 | loss: 0.00784 - accuracy: 0.99867
Validating epoch 2 | loss: 1.20575 - accuracy: 0.845
Training epoch 3 | loss: 0.00271 - accuracy: 0.99956
Validating epoch 3 | loss: 0.92813 - accuracy: 0.887
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.8, small_label is 0, small_prop is 0.1, balance_seed is 0
4500 4500
4500 450
4500 4500
Training epoch 0 | loss: 0.19305 - accuracy: 0.93156
Validating epoch 0 | loss: 0.44493 - accuracy: 0.928
132.951 s/it
Training epoch 1 | loss: 0.02477 - accuracy: 0.99533
Validating epoch 1 | loss: 2.01117 - accuracy: 0.764
Training epoch 2 | loss: 0.00725 - accuracy: 0.99878
Validating epoch 2 | loss: 1.15953 - accuracy: 0.868
Training epoch 3 | loss: 0.00211 - accuracy: 0.99956
Validating epoch 3 | loss: 1.30073 - accuracy: 0.86
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.9, small_label is 0, small_prop is 0.1, balance_seed is 0
4500 4500
4500 450
4500 4500
Training epoch 0 | loss: 0.18136 - accuracy: 0.93911
Validating epoch 0 | loss: 0.93195 - accuracy: 0.855
124.654 s/it
Training epoch 1 | loss: 0.02782 - accuracy: 0.99456
Validating epoch 1 | loss: 1.41284 - accuracy: 0.809
Training epoch 2 | loss: 0.00316 - accuracy: 0.99933
Validating epoch 2 | loss: 1.28714 - accuracy: 0.856
Training epoch 3 | loss: 0.00115 - accuracy: 0.99978
Validating epoch 3 | loss: 1.06704 - accuracy: 0.88
Model is Bert, dataset is subj, undersample is False, aug mode is None, geo is 0.5, small_label is 1, small_prop is 0.1, balance_seed is 0
4500 4500
4500 450
4500 4500
Training epoch 0 | loss: 0.15425 - accuracy: 0.94144
Validating epoch 0 | loss: 0.6132 - accuracy: 0.904
109.25 s/it
Training epoch 1 | loss: 0.01545 - accuracy: 0.99756
Validating epoch 1 | loss: 0.77621 - accuracy: 0.9
Training epoch 2 | loss: 0.00248 - accuracy: 0.99956
Validating epoch 2 | loss: 0.88996 - accuracy: 0.899
Training epoch 3 | loss: 0.00061 - accuracy: 0.99989
Validating epoch 3 | loss: 0.94791 - accuracy: 0.897
Model is Bert, dataset is subj, undersample is True, aug mode is None, geo is 0.5, small_label is 1, small_prop is 0.1, balance_seed is 0
4500 4500
4500 450
450 450
Training epoch 0 | loss: 0.41308 - accuracy: 0.79333
Validating epoch 0 | loss: 0.23789 - accuracy: 0.927
13.519 s/it
Training epoch 1 | loss: 0.1164 - accuracy: 0.96889
Validating epoch 1 | loss: 0.2825 - accuracy: 0.938
Training epoch 2 | loss: 0.05554 - accuracy: 0.98556
Validating epoch 2 | loss: 0.29555 - accuracy: 0.941
Training epoch 3 | loss: 0.02473 - accuracy: 0.99444
Validating epoch 3 | loss: 0.31181 - accuracy: 0.94
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.5, small_label is 1, small_prop is 0.1, balance_seed is 0
4500 4500
4500 450
4500 4500
Training epoch 0 | loss: 0.18375 - accuracy: 0.93211
Validating epoch 0 | loss: 0.77103 - accuracy: 0.888
166.195 s/it
Training epoch 1 | loss: 0.0242 - accuracy: 0.99533
Validating epoch 1 | loss: 0.57557 - accuracy: 0.92
Training epoch 2 | loss: 0.00789 - accuracy: 0.99856
Validating epoch 2 | loss: 0.82405 - accuracy: 0.898
Training epoch 3 | loss: 0.00161 - accuracy: 0.99967
Validating epoch 3 | loss: 0.66524 - accuracy: 0.926
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.6, small_label is 1, small_prop is 0.1, balance_seed is 0
4500 4500
4500 450
4500 4500
Training epoch 0 | loss: 0.17203 - accuracy: 0.93733
Validating epoch 0 | loss: 0.43841 - accuracy: 0.934
144.01 s/it
Training epoch 1 | loss: 0.02153 - accuracy: 0.996
Validating epoch 1 | loss: 0.70661 - accuracy: 0.913
Training epoch 2 | loss: 0.00635 - accuracy: 0.999
Validating epoch 2 | loss: 0.60779 - accuracy: 0.927
Training epoch 3 | loss: 0.00212 - accuracy: 0.99967
Validating epoch 3 | loss: 0.80822 - accuracy: 0.907
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.7, small_label is 1, small_prop is 0.1, balance_seed is 0
4500 4500
4500 450
4500 4500
Training epoch 0 | loss: 0.18048 - accuracy: 0.93156
Validating epoch 0 | loss: 0.58278 - accuracy: 0.917
135.039 s/it
Training epoch 1 | loss: 0.02055 - accuracy: 0.99611
Validating epoch 1 | loss: 0.84859 - accuracy: 0.9
Training epoch 2 | loss: 0.00869 - accuracy: 0.99844
Validating epoch 2 | loss: 0.66747 - accuracy: 0.924
Training epoch 3 | loss: 0.00352 - accuracy: 0.99944
Validating epoch 3 | loss: 0.79223 - accuracy: 0.915
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.8, small_label is 1, small_prop is 0.1, balance_seed is 0
4500 4500
4500 450
4500 4500
Training epoch 0 | loss: 0.15639 - accuracy: 0.94011
Validating epoch 0 | loss: 0.51179 - accuracy: 0.927
126.257 s/it
Training epoch 1 | loss: 0.02416 - accuracy: 0.99533
Validating epoch 1 | loss: 0.72254 - accuracy: 0.912
Training epoch 2 | loss: 0.00588 - accuracy: 0.99889
Validating epoch 2 | loss: 0.77662 - accuracy: 0.911
Training epoch 3 | loss: 0.00252 - accuracy: 0.99967
Validating epoch 3 | loss: 0.81224 - accuracy: 0.911
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.9, small_label is 1, small_prop is 0.1, balance_seed is 0
4500 4500
4500 450
4500 4500
Training epoch 0 | loss: 0.17086 - accuracy: 0.93656
Validating epoch 0 | loss: 0.69233 - accuracy: 0.896
116.469 s/it
Training epoch 1 | loss: 0.01811 - accuracy: 0.99656
Validating epoch 1 | loss: 0.63153 - accuracy: 0.917
Training epoch 2 | loss: 0.00484 - accuracy: 0.99911
Validating epoch 2 | loss: 0.84533 - accuracy: 0.898
Training epoch 3 | loss: 6e-05 - accuracy: 1.0
Validating epoch 3 | loss: 0.79965 - accuracy: 0.908
Model is Bert, dataset is subj, undersample is False, aug mode is None, geo is 0.5, small_label is 0, small_prop is 0.2, balance_seed is 0
4500 4500
4500 900
4500 4500
Training epoch 0 | loss: 0.22735 - accuracy: 0.91433
Validating epoch 0 | loss: 0.38867 - accuracy: 0.927
106.99 s/it
Training epoch 1 | loss: 0.03565 - accuracy: 0.99333
Validating epoch 1 | loss: 0.49157 - accuracy: 0.925
Training epoch 2 | loss: 0.00768 - accuracy: 0.99856
Validating epoch 2 | loss: 0.61517 - accuracy: 0.924
Training epoch 3 | loss: 0.00214 - accuracy: 0.99944
Validating epoch 3 | loss: 0.74497 - accuracy: 0.914
Model is Bert, dataset is subj, undersample is True, aug mode is None, geo is 0.5, small_label is 0, small_prop is 0.2, balance_seed is 0
4500 4500
4500 900
900 900
Training epoch 0 | loss: 0.40767 - accuracy: 0.82389
Validating epoch 0 | loss: 0.3083 - accuracy: 0.919
23.673 s/it
Training epoch 1 | loss: 0.1356 - accuracy: 0.96778
Validating epoch 1 | loss: 0.27847 - accuracy: 0.937
Training epoch 2 | loss: 0.03517 - accuracy: 0.98889
Validating epoch 2 | loss: 0.31585 - accuracy: 0.942
Training epoch 3 | loss: 0.00512 - accuracy: 0.99833
Validating epoch 3 | loss: 0.34557 - accuracy: 0.942
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.5, small_label is 0, small_prop is 0.2, balance_seed is 0
4500 4500
4500 900
4500 4500
Training epoch 0 | loss: 0.21533 - accuracy: 0.92656
Validating epoch 0 | loss: 0.40523 - accuracy: 0.906
153.965 s/it
Training epoch 1 | loss: 0.0473 - accuracy: 0.991
Validating epoch 1 | loss: 0.94868 - accuracy: 0.859
Training epoch 2 | loss: 0.01083 - accuracy: 0.99811
Validating epoch 2 | loss: 0.70542 - accuracy: 0.911
Training epoch 3 | loss: 0.00286 - accuracy: 0.99944
Validating epoch 3 | loss: 0.777 - accuracy: 0.908
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.6, small_label is 0, small_prop is 0.2, balance_seed is 0
4500 4500
4500 900
4500 4500
Training epoch 0 | loss: 0.2185 - accuracy: 0.92222
Validating epoch 0 | loss: 0.44744 - accuracy: 0.927
141.879 s/it
Training epoch 1 | loss: 0.04229 - accuracy: 0.99133
Validating epoch 1 | loss: 0.40617 - accuracy: 0.94
Training epoch 2 | loss: 0.00983 - accuracy: 0.998
Validating epoch 2 | loss: 0.81081 - accuracy: 0.904
Training epoch 3 | loss: 0.00459 - accuracy: 0.99933
Validating epoch 3 | loss: 0.66886 - accuracy: 0.922
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.7, small_label is 0, small_prop is 0.2, balance_seed is 0
4500 4500
4500 900
4500 4500
Training epoch 0 | loss: 0.22587 - accuracy: 0.92067
Validating epoch 0 | loss: 0.40365 - accuracy: 0.913
133.917 s/it
Training epoch 1 | loss: 0.04246 - accuracy: 0.99156
Validating epoch 1 | loss: 0.90651 - accuracy: 0.88
Training epoch 2 | loss: 0.01076 - accuracy: 0.99822
Validating epoch 2 | loss: 0.60297 - accuracy: 0.926
Training epoch 3 | loss: 0.00322 - accuracy: 0.99956
Validating epoch 3 | loss: 0.71081 - accuracy: 0.915
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.8, small_label is 0, small_prop is 0.2, balance_seed is 0
4500 4500
4500 900
4500 4500
Training epoch 0 | loss: 0.21672 - accuracy: 0.93311
Validating epoch 0 | loss: 0.62598 - accuracy: 0.901
125.972 s/it
Training epoch 1 | loss: 0.03798 - accuracy: 0.99244
Validating epoch 1 | loss: 0.80163 - accuracy: 0.884
Training epoch 2 | loss: 0.01133 - accuracy: 0.99756
Validating epoch 2 | loss: 0.75236 - accuracy: 0.906
Training epoch 3 | loss: 0.00219 - accuracy: 0.99933
Validating epoch 3 | loss: 0.73576 - accuracy: 0.915
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.9, small_label is 0, small_prop is 0.2, balance_seed is 0
4500 4500
4500 900
4500 4500
Training epoch 0 | loss: 0.22149 - accuracy: 0.92478
Validating epoch 0 | loss: 0.35023 - accuracy: 0.936
115.888 s/it
Training epoch 1 | loss: 0.04476 - accuracy: 0.99167
Validating epoch 1 | loss: 0.68231 - accuracy: 0.908
Training epoch 2 | loss: 0.00921 - accuracy: 0.99856
Validating epoch 2 | loss: 0.68297 - accuracy: 0.917
Training epoch 3 | loss: 0.00128 - accuracy: 0.99978
Validating epoch 3 | loss: 0.65144 - accuracy: 0.921
Model is Bert, dataset is subj, undersample is False, aug mode is None, geo is 0.5, small_label is 1, small_prop is 0.2, balance_seed is 0
4500 4500
4500 900
4500 4500
Traceback (most recent call last):
  File "experiments/bal_bert_syn_subj.py", line 45, in <module>
    experiment(balance_seed)
  File "experiments/bal_bert_syn_subj.py", line 34, in experiment
    agent.run()
  File "/u6/dltammin/thesis/agents/bert.py", line 86, in run
    self.train()
  File "/u6/dltammin/thesis/agents/bert.py", line 103, in train
    self.train_one_epoch()
  File "/u6/dltammin/thesis/agents/bert.py", line 126, in train_one_epoch
    x, attention_mask=attention_mask, labels=y)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 1161, in forward
    inputs_embeds=inputs_embeds,
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 811, in forward
    encoder_attention_mask=encoder_extended_attention_mask,
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 422, in forward
    hidden_states, attention_mask, head_mask[i], encoder_hidden_states, encoder_attention_mask
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 394, in forward
    intermediate_output = self.intermediate(attention_output)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 347, in forward
    hidden_states = self.intermediate_act_fn(hidden_states)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 134, in gelu
    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 1; 22.38 GiB total capacity; 20.26 GiB already allocated; 8.06 MiB free; 1.50 GiB cached)
