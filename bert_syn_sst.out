  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:36<01:48, 36.12s/it] 50%|█████     | 2/4 [01:11<01:12, 36.02s/it] 75%|███████▌  | 3/4 [01:47<00:35, 35.84s/it]100%|██████████| 4/4 [02:22<00:00, 35.69s/it]100%|██████████| 4/4 [02:22<00:00, 35.67s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:18<00:54, 18.14s/it] 50%|█████     | 2/4 [00:36<00:36, 18.13s/it] 75%|███████▌  | 3/4 [00:54<00:18, 18.09s/it]100%|██████████| 4/4 [01:12<00:00, 18.00s/it]100%|██████████| 4/4 [01:12<00:00, 18.01s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:25<04:15, 85.17s/it] 50%|█████     | 2/4 [02:47<02:48, 84.36s/it] 75%|███████▌  | 3/4 [04:09<01:23, 83.62s/it]100%|██████████| 4/4 [05:32<00:00, 83.44s/it]100%|██████████| 4/4 [05:32<00:00, 83.14s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:13<03:39, 73.28s/it] 50%|█████     | 2/4 [02:25<02:25, 72.87s/it] 75%|███████▌  | 3/4 [03:37<01:12, 72.70s/it]100%|██████████| 4/4 [04:48<00:00, 72.32s/it]100%|██████████| 4/4 [04:48<00:00, 72.23s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:09<03:28, 69.36s/it] 50%|█████     | 2/4 [02:18<02:18, 69.36s/it] 75%|███████▌  | 3/4 [03:28<01:09, 69.38s/it]100%|██████████| 4/4 [04:34<00:00, 68.61s/it]100%|██████████| 4/4 [04:34<00:00, 68.74s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:59<02:59, 59.98s/it] 50%|█████     | 2/4 [02:00<02:00, 60.04s/it] 75%|███████▌  | 3/4 [03:01<01:00, 60.29s/it]100%|██████████| 4/4 [04:01<00:00, 60.40s/it]100%|██████████| 4/4 [04:01<00:00, 60.42s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:55<02:45, 55.16s/it] 50%|█████     | 2/4 [01:51<01:51, 55.50s/it] 75%|███████▌  | 3/4 [02:46<00:55, 55.48s/it]100%|██████████| 4/4 [03:42<00:00, 55.65s/it]100%|██████████| 4/4 [03:42<00:00, 55.73s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:49<02:29, 49.99s/it] 50%|█████     | 2/4 [01:39<01:39, 49.97s/it] 75%|███████▌  | 3/4 [02:29<00:49, 49.76s/it]100%|██████████| 4/4 [03:18<00:00, 49.61s/it]100%|██████████| 4/4 [03:18<00:00, 49.61s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:43<02:11, 43.93s/it] 50%|█████     | 2/4 [01:26<01:27, 43.53s/it] 75%|███████▌  | 3/4 [02:08<00:42, 42.94s/it]100%|██████████| 4/4 [02:49<00:00, 42.50s/it]100%|██████████| 4/4 [02:49<00:00, 42.39s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:36<01:49, 36.46s/it] 50%|█████     | 2/4 [01:12<01:12, 36.42s/it] 75%|███████▌  | 3/4 [01:48<00:36, 36.26s/it]100%|██████████| 4/4 [02:24<00:00, 36.10s/it]100%|██████████| 4/4 [02:24<00:00, 36.10s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:19<00:58, 19.67s/it] 50%|█████     | 2/4 [00:39<00:39, 19.65s/it] 75%|███████▌  | 3/4 [00:58<00:19, 19.58s/it]100%|██████████| 4/4 [01:17<00:00, 19.49s/it]100%|██████████| 4/4 [01:17<00:00, 19.50s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:28<04:24, 88.04s/it] 50%|█████     | 2/4 [02:54<02:55, 87.63s/it] 75%|███████▌  | 3/4 [04:20<01:27, 87.02s/it]100%|██████████| 4/4 [05:46<00:00, 86.85s/it]100%|██████████| 4/4 [05:46<00:00, 86.69s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:19<03:59, 79.76s/it] 50%|█████     | 2/4 [02:39<02:39, 79.68s/it] 75%|███████▌  | 3/4 [03:57<01:19, 79.20s/it]100%|██████████| 4/4 [05:15<00:00, 78.91s/it]100%|██████████| 4/4 [05:15<00:00, 78.89s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:11<03:34, 71.62s/it] 50%|█████     | 2/4 [02:24<02:24, 72.00s/it] 75%|███████▌  | 3/4 [03:35<01:11, 71.73s/it]100%|██████████| 4/4 [04:47<00:00, 71.87s/it]100%|██████████| 4/4 [04:47<00:00, 71.95s/it]
  0%|          | 0/4 [00:00<?, ?it/s]  0%|          | 0/4 [00:00<?, ?it/s]
Model is Bert, dataset is sst, undersample is False, aug mode is None, geo is 0.5, small_label is 0, small_prop is 0.5, balance_seed is 0
3610 3310
3610 1655
3610 3310
Training epoch 0 | loss: 0.35383 - accuracy: 0.84595
Validating epoch 0 | loss: 0.56491 - accuracy: 0.8406
36.118 s/it
Training epoch 1 | loss: 0.12011 - accuracy: 0.96402
Validating epoch 1 | loss: 0.48555 - accuracy: 0.88417
Training epoch 2 | loss: 0.03706 - accuracy: 0.99046
Validating epoch 2 | loss: 0.87889 - accuracy: 0.84862
Training epoch 3 | loss: 0.00947 - accuracy: 0.99812
Validating epoch 3 | loss: 0.85157 - accuracy: 0.87615
Model is Bert, dataset is sst, undersample is True, aug mode is None, geo is 0.5, small_label is 0, small_prop is 0.5, balance_seed is 0
3610 3310
3610 1655
1655 1655
Training epoch 0 | loss: 0.42205 - accuracy: 0.80755
Validating epoch 0 | loss: 0.3512 - accuracy: 0.85436
18.145 s/it
Training epoch 1 | loss: 0.16959 - accuracy: 0.9429
Validating epoch 1 | loss: 0.46705 - accuracy: 0.87615
Training epoch 2 | loss: 0.06052 - accuracy: 0.98006
Validating epoch 2 | loss: 0.64504 - accuracy: 0.87844
Training epoch 3 | loss: 0.02774 - accuracy: 0.99426
Validating epoch 3 | loss: 0.70844 - accuracy: 0.87615
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.3, small_label is 0, small_prop is 0.5, balance_seed is 0
3610 3310
3610 1655
3610 3310
Training epoch 0 | loss: 0.31905 - accuracy: 0.86026
Validating epoch 0 | loss: 0.4785 - accuracy: 0.8406
85.168 s/it
Training epoch 1 | loss: 0.11704 - accuracy: 0.95737
Validating epoch 1 | loss: 0.54112 - accuracy: 0.8406
Training epoch 2 | loss: 0.04145 - accuracy: 0.98844
Validating epoch 2 | loss: 0.75595 - accuracy: 0.8578
Training epoch 3 | loss: 0.01984 - accuracy: 0.99523
Validating epoch 3 | loss: 0.88758 - accuracy: 0.84862
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.4, small_label is 0, small_prop is 0.5, balance_seed is 0
3610 3310
3610 1655
3610 3310
Training epoch 0 | loss: 0.35403 - accuracy: 0.84393
Validating epoch 0 | loss: 0.49448 - accuracy: 0.81766
73.285 s/it
Training epoch 1 | loss: 0.12767 - accuracy: 0.95592
Validating epoch 1 | loss: 0.86132 - accuracy: 0.79014
Training epoch 2 | loss: 0.05312 - accuracy: 0.98425
Validating epoch 2 | loss: 0.67568 - accuracy: 0.86583
Training epoch 3 | loss: 0.01709 - accuracy: 0.99566
Validating epoch 3 | loss: 0.8626 - accuracy: 0.85894
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.5, small_label is 0, small_prop is 0.5, balance_seed is 0
3610 3310
3610 1655
3610 3310
Training epoch 0 | loss: 0.34652 - accuracy: 0.85202
Validating epoch 0 | loss: 0.35441 - accuracy: 0.86124
69.362 s/it
Training epoch 1 | loss: 0.11586 - accuracy: 0.96214
Validating epoch 1 | loss: 0.6858 - accuracy: 0.8406
Training epoch 2 | loss: 0.03367 - accuracy: 0.99075
Validating epoch 2 | loss: 0.82112 - accuracy: 0.84977
Training epoch 3 | loss: 0.01265 - accuracy: 0.99711
Validating epoch 3 | loss: 0.90423 - accuracy: 0.85436
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.6, small_label is 0, small_prop is 0.5, balance_seed is 0
3610 3310
3610 1655
3610 3310
Training epoch 0 | loss: 0.34935 - accuracy: 0.84855
Validating epoch 0 | loss: 0.43718 - accuracy: 0.84289
59.978 s/it
Training epoch 1 | loss: 0.10886 - accuracy: 0.96474
Validating epoch 1 | loss: 0.5769 - accuracy: 0.87156
Training epoch 2 | loss: 0.04345 - accuracy: 0.98699
Validating epoch 2 | loss: 0.85078 - accuracy: 0.85206
Training epoch 3 | loss: 0.01305 - accuracy: 0.99581
Validating epoch 3 | loss: 0.87028 - accuracy: 0.86353
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.7, small_label is 0, small_prop is 0.5, balance_seed is 0
3610 3310
3610 1655
3610 3310
Training epoch 0 | loss: 0.34864 - accuracy: 0.8448
Validating epoch 0 | loss: 0.35624 - accuracy: 0.86583
55.164 s/it
Training epoch 1 | loss: 0.12515 - accuracy: 0.96026
Validating epoch 1 | loss: 0.78217 - accuracy: 0.83142
Training epoch 2 | loss: 0.03322 - accuracy: 0.99118
Validating epoch 2 | loss: 0.81379 - accuracy: 0.84862
Training epoch 3 | loss: 0.01059 - accuracy: 0.99783
Validating epoch 3 | loss: 0.92985 - accuracy: 0.84633
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.8, small_label is 0, small_prop is 0.5, balance_seed is 0
3610 3310
3610 1655
3610 3310
Training epoch 0 | loss: 0.36309 - accuracy: 0.83873
Validating epoch 0 | loss: 0.32397 - accuracy: 0.86697
49.994 s/it
Training epoch 1 | loss: 0.135 - accuracy: 0.95751
Validating epoch 1 | loss: 0.59484 - accuracy: 0.84748
Training epoch 2 | loss: 0.05388 - accuracy: 0.98555
Validating epoch 2 | loss: 0.83369 - accuracy: 0.83601
Training epoch 3 | loss: 0.02106 - accuracy: 0.99509
Validating epoch 3 | loss: 0.81288 - accuracy: 0.86009
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.9, small_label is 0, small_prop is 0.5, balance_seed is 0
3610 3310
3610 1655
3610 3310
Training epoch 0 | loss: 0.3825 - accuracy: 0.83208
Validating epoch 0 | loss: 0.3752 - accuracy: 0.86468
43.932 s/it
Training epoch 1 | loss: 0.13084 - accuracy: 0.95838
Validating epoch 1 | loss: 0.75172 - accuracy: 0.84977
Training epoch 2 | loss: 0.0406 - accuracy: 0.9896
Validating epoch 2 | loss: 0.7913 - accuracy: 0.86812
Training epoch 3 | loss: 0.01727 - accuracy: 0.99624
Validating epoch 3 | loss: 0.81729 - accuracy: 0.86353
Model is Bert, dataset is sst, undersample is False, aug mode is None, geo is 0.5, small_label is 1, small_prop is 0.5, balance_seed is 0
3310 3610
3310 1805
3310 3610
Training epoch 0 | loss: 0.35849 - accuracy: 0.84538
Validating epoch 0 | loss: 0.38924 - accuracy: 0.87156
36.46 s/it
Training epoch 1 | loss: 0.11327 - accuracy: 0.96315
Validating epoch 1 | loss: 0.57942 - accuracy: 0.85665
Training epoch 2 | loss: 0.03153 - accuracy: 0.99205
Validating epoch 2 | loss: 0.74496 - accuracy: 0.87385
Training epoch 3 | loss: 0.00955 - accuracy: 0.99783
Validating epoch 3 | loss: 0.80148 - accuracy: 0.87385
Model is Bert, dataset is sst, undersample is True, aug mode is None, geo is 0.5, small_label is 1, small_prop is 0.5, balance_seed is 0
3310 3610
3310 1805
1805 1805
Training epoch 0 | loss: 0.4313 - accuracy: 0.78532
Validating epoch 0 | loss: 0.32954 - accuracy: 0.86124
19.667 s/it
Training epoch 1 | loss: 0.16448 - accuracy: 0.94238
Validating epoch 1 | loss: 0.38393 - accuracy: 0.87041
Training epoch 2 | loss: 0.0536 - accuracy: 0.9856
Validating epoch 2 | loss: 0.72857 - accuracy: 0.86468
Training epoch 3 | loss: 0.01982 - accuracy: 0.99474
Validating epoch 3 | loss: 0.7644 - accuracy: 0.86812
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.3, small_label is 1, small_prop is 0.5, balance_seed is 0
3310 3610
3310 1805
3310 3610
Training epoch 0 | loss: 0.33415 - accuracy: 0.85621
Validating epoch 0 | loss: 0.35915 - accuracy: 0.86583
88.039 s/it
Training epoch 1 | loss: 0.11754 - accuracy: 0.96315
Validating epoch 1 | loss: 0.46047 - accuracy: 0.86697
Training epoch 2 | loss: 0.04236 - accuracy: 0.98815
Validating epoch 2 | loss: 0.55785 - accuracy: 0.87729
Training epoch 3 | loss: 0.01825 - accuracy: 0.99523
Validating epoch 3 | loss: 0.7189 - accuracy: 0.87844
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.4, small_label is 1, small_prop is 0.5, balance_seed is 0
3310 3610
3310 1805
3310 3610
Training epoch 0 | loss: 0.34081 - accuracy: 0.84971
Validating epoch 0 | loss: 0.35887 - accuracy: 0.86927
79.759 s/it
Training epoch 1 | loss: 0.10616 - accuracy: 0.9659
Validating epoch 1 | loss: 0.4257 - accuracy: 0.87156
Training epoch 2 | loss: 0.04035 - accuracy: 0.98873
Validating epoch 2 | loss: 0.74323 - accuracy: 0.86583
Training epoch 3 | loss: 0.01528 - accuracy: 0.9961
Validating epoch 3 | loss: 0.80937 - accuracy: 0.86697
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.5, small_label is 1, small_prop is 0.5, balance_seed is 0
3310 3610
3310 1805
3310 3610
Training epoch 0 | loss: 0.34899 - accuracy: 0.84827
Validating epoch 0 | loss: 0.34932 - accuracy: 0.86927
71.624 s/it
Training epoch 1 | loss: 0.10664 - accuracy: 0.96402
Validating epoch 1 | loss: 0.55863 - accuracy: 0.84748
Training epoch 2 | loss: 0.04568 - accuracy: 0.98743
Validating epoch 2 | loss: 0.73219 - accuracy: 0.86239
Training epoch 3 | loss: 0.01442 - accuracy: 0.99639
Validating epoch 3 | loss: 0.73771 - accuracy: 0.86927
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.6, small_label is 1, small_prop is 0.5, balance_seed is 0
3310 3610
3310 1805
3310 3610
Traceback (most recent call last):
  File "experiments/bert_syn_sst.py", line 41, in <module>
    experiment(balance_seed)
  File "experiments/bert_syn_sst.py", line 37, in experiment
    agent.run()
  File "/u6/dltammin/thesis/agents/bert.py", line 89, in run
    self.train()
  File "/u6/dltammin/thesis/agents/bert.py", line 108, in train
    self.train_one_epoch()
  File "/u6/dltammin/thesis/agents/bert.py", line 131, in train_one_epoch
    x, attention_mask=attention_mask, labels=y)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 1161, in forward
    inputs_embeds=inputs_embeds,
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 811, in forward
    encoder_attention_mask=encoder_extended_attention_mask,
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 422, in forward
    hidden_states, attention_mask, head_mask[i], encoder_hidden_states, encoder_attention_mask
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 394, in forward
    intermediate_output = self.intermediate(attention_output)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 347, in forward
    hidden_states = self.intermediate_act_fn(hidden_states)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 134, in gelu
    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 22.38 GiB total capacity; 20.22 GiB already allocated; 8.06 MiB free; 1.54 GiB cached)
