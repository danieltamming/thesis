  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:47<02:22, 47.50s/it] 50%|█████     | 2/4 [01:34<01:34, 47.21s/it] 75%|███████▌  | 3/4 [02:20<00:46, 46.90s/it]100%|██████████| 4/4 [03:06<00:00, 46.69s/it]100%|██████████| 4/4 [03:06<00:00, 46.60s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:24<01:12, 24.26s/it] 50%|█████     | 2/4 [00:48<00:48, 24.20s/it] 75%|███████▌  | 3/4 [01:12<00:24, 24.10s/it]100%|██████████| 4/4 [01:35<00:00, 24.00s/it]100%|██████████| 4/4 [01:35<00:00, 23.99s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:57<05:52, 117.44s/it] 50%|█████     | 2/4 [03:51<03:52, 116.33s/it] 75%|███████▌  | 3/4 [05:43<01:55, 115.24s/it]100%|██████████| 4/4 [07:36<00:00, 114.35s/it]100%|██████████| 4/4 [07:36<00:00, 114.04s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:43<05:10, 103.48s/it] 50%|█████     | 2/4 [03:25<03:26, 103.03s/it] 75%|███████▌  | 3/4 [05:07<01:42, 102.69s/it]100%|██████████| 4/4 [06:49<00:00, 102.61s/it]100%|██████████| 4/4 [06:49<00:00, 102.44s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:34<04:43, 94.42s/it] 50%|█████     | 2/4 [03:08<03:08, 94.37s/it] 75%|███████▌  | 3/4 [04:42<01:34, 94.19s/it]100%|██████████| 4/4 [06:14<00:00, 93.65s/it]100%|██████████| 4/4 [06:14<00:00, 93.71s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:25<04:16, 85.55s/it] 50%|█████     | 2/4 [02:50<02:50, 85.36s/it] 75%|███████▌  | 3/4 [04:14<01:24, 84.83s/it]100%|██████████| 4/4 [05:38<00:00, 84.66s/it]100%|██████████| 4/4 [05:38<00:00, 84.59s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:14<03:43, 74.58s/it] 50%|█████     | 2/4 [02:29<02:29, 74.59s/it] 75%|███████▌  | 3/4 [03:43<01:14, 74.54s/it]100%|██████████| 4/4 [04:59<00:00, 74.94s/it]100%|██████████| 4/4 [04:59<00:00, 74.87s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:06<03:20, 66.67s/it] 50%|█████     | 2/4 [02:12<02:13, 66.54s/it] 75%|███████▌  | 3/4 [03:19<01:06, 66.45s/it]100%|██████████| 4/4 [04:25<00:00, 66.42s/it]100%|██████████| 4/4 [04:25<00:00, 66.38s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:56<02:48, 56.07s/it] 50%|█████     | 2/4 [01:53<01:52, 56.34s/it] 75%|███████▌  | 3/4 [02:48<00:56, 56.04s/it]100%|██████████| 4/4 [03:44<00:00, 55.97s/it]100%|██████████| 4/4 [03:44<00:00, 56.05s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:47<02:21, 47.19s/it] 50%|█████     | 2/4 [01:33<01:34, 47.01s/it] 75%|███████▌  | 3/4 [02:20<00:46, 46.81s/it]100%|██████████| 4/4 [03:06<00:00, 46.61s/it]100%|██████████| 4/4 [03:06<00:00, 46.57s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:24<01:13, 24.36s/it] 50%|█████     | 2/4 [00:48<00:48, 24.32s/it] 75%|███████▌  | 3/4 [01:12<00:24, 24.24s/it]100%|██████████| 4/4 [01:36<00:00, 24.14s/it]100%|██████████| 4/4 [01:36<00:00, 24.13s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:58<05:54, 118.23s/it] 50%|█████     | 2/4 [03:55<03:55, 117.80s/it] 75%|███████▌  | 3/4 [05:51<01:57, 117.48s/it]100%|██████████| 4/4 [07:49<00:00, 117.52s/it]100%|██████████| 4/4 [07:49<00:00, 117.35s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:46<05:20, 106.97s/it] 50%|█████     | 2/4 [03:33<03:33, 106.71s/it] 75%|███████▌  | 3/4 [05:18<01:46, 106.45s/it]100%|██████████| 4/4 [07:04<00:00, 106.31s/it]100%|██████████| 4/4 [07:04<00:00, 106.22s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:38<04:56, 98.93s/it] 50%|█████     | 2/4 [03:15<03:16, 98.22s/it] 75%|███████▌  | 3/4 [04:52<01:37, 97.73s/it]100%|██████████| 4/4 [06:28<00:00, 97.32s/it]100%|██████████| 4/4 [06:28<00:00, 97.12s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:28<04:25, 88.36s/it] 50%|█████     | 2/4 [02:55<02:56, 88.11s/it] 75%|███████▌  | 3/4 [04:22<01:27, 87.59s/it]100%|██████████| 4/4 [05:48<00:00, 87.32s/it]100%|██████████| 4/4 [05:48<00:00, 87.24s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:17<03:51, 77.25s/it] 50%|█████     | 2/4 [02:34<02:34, 77.40s/it] 75%|███████▌  | 3/4 [03:50<01:16, 76.85s/it]100%|██████████| 4/4 [05:06<00:00, 76.54s/it]100%|██████████| 4/4 [05:06<00:00, 76.59s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:07<03:22, 67.40s/it] 50%|█████     | 2/4 [02:15<02:15, 67.67s/it] 75%|███████▌  | 3/4 [03:22<01:07, 67.27s/it]100%|██████████| 4/4 [04:27<00:00, 66.78s/it]100%|██████████| 4/4 [04:27<00:00, 66.92s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:57<02:53, 57.89s/it] 50%|█████     | 2/4 [01:54<01:54, 57.40s/it] 75%|███████▌  | 3/4 [02:49<00:56, 56.88s/it]100%|██████████| 4/4 [03:45<00:00, 56.64s/it]100%|██████████| 4/4 [03:45<00:00, 56.47s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:47<02:21, 47.29s/it] 50%|█████     | 2/4 [01:34<01:34, 47.12s/it] 75%|███████▌  | 3/4 [02:20<00:46, 46.92s/it]100%|██████████| 4/4 [03:06<00:00, 46.74s/it]100%|██████████| 4/4 [03:06<00:00, 46.70s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:24<01:12, 24.30s/it] 50%|█████     | 2/4 [00:48<00:48, 24.26s/it] 75%|███████▌  | 3/4 [01:12<00:24, 24.17s/it]100%|██████████| 4/4 [01:36<00:00, 24.10s/it]100%|██████████| 4/4 [01:36<00:00, 24.09s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:54<05:42, 114.10s/it] 50%|█████     | 2/4 [03:47<03:47, 113.90s/it] 75%|███████▌  | 3/4 [05:40<01:53, 113.73s/it]100%|██████████| 4/4 [07:33<00:00, 113.54s/it]100%|██████████| 4/4 [07:33<00:00, 113.49s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:43<05:11, 103.67s/it] 50%|█████     | 2/4 [03:27<03:27, 103.73s/it] 75%|███████▌  | 3/4 [05:11<01:43, 103.77s/it]100%|██████████| 4/4 [06:55<00:00, 103.74s/it]100%|██████████| 4/4 [06:55<00:00, 103.76s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:34<04:44, 94.98s/it] 50%|█████     | 2/4 [03:09<03:09, 94.89s/it] 75%|███████▌  | 3/4 [04:44<01:34, 94.90s/it]100%|██████████| 4/4 [06:19<00:00, 94.93s/it]100%|██████████| 4/4 [06:19<00:00, 94.90s/it]
  0%|          | 0/4 [00:00<?, ?it/s]  0%|          | 0/4 [00:00<?, ?it/s]
Model is Bert, dataset is subj, undersample is False, aug mode is None, geo is 0.5, small_label is 0, small_prop is 0.5, balance_seed is 0
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.16117 - accuracy: 0.94478
Validating epoch 0 | loss: 0.18831 - accuracy: 0.943
47.503 s/it
Training epoch 1 | loss: 0.04817 - accuracy: 0.98822
Validating epoch 1 | loss: 0.2569 - accuracy: 0.938
Training epoch 2 | loss: 0.01367 - accuracy: 0.99678
Validating epoch 2 | loss: 0.33397 - accuracy: 0.944
Training epoch 3 | loss: 0.00212 - accuracy: 0.99933
Validating epoch 3 | loss: 0.33997 - accuracy: 0.948
Model is Bert, dataset is subj, undersample is True, aug mode is None, geo is 0.5, small_label is 0, small_prop is 0.5, balance_seed is 0
4500 4500
4500 2250
2250 2250
Training epoch 0 | loss: 0.22089 - accuracy: 0.922
Validating epoch 0 | loss: 0.2119 - accuracy: 0.937
24.257 s/it
Training epoch 1 | loss: 0.06694 - accuracy: 0.97933
Validating epoch 1 | loss: 0.22899 - accuracy: 0.949
Training epoch 2 | loss: 0.02168 - accuracy: 0.99511
Validating epoch 2 | loss: 0.23086 - accuracy: 0.953
Training epoch 3 | loss: 0.0064 - accuracy: 0.99844
Validating epoch 3 | loss: 0.29909 - accuracy: 0.947
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.3, small_label is 0, small_prop is 0.5, balance_seed is 0
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.15953 - accuracy: 0.947
Validating epoch 0 | loss: 0.32003 - accuracy: 0.921
117.436 s/it
Training epoch 1 | loss: 0.05179 - accuracy: 0.98567
Validating epoch 1 | loss: 0.31386 - accuracy: 0.926
Training epoch 2 | loss: 0.0114 - accuracy: 0.99667
Validating epoch 2 | loss: 0.43471 - accuracy: 0.932
Training epoch 3 | loss: 0.00305 - accuracy: 0.999
Validating epoch 3 | loss: 0.38573 - accuracy: 0.94
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.4, small_label is 0, small_prop is 0.5, balance_seed is 0
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.15171 - accuracy: 0.94456
Validating epoch 0 | loss: 0.30649 - accuracy: 0.911
103.482 s/it
Training epoch 1 | loss: 0.03574 - accuracy: 0.98989
Validating epoch 1 | loss: 0.24871 - accuracy: 0.946
Training epoch 2 | loss: 0.01362 - accuracy: 0.997
Validating epoch 2 | loss: 0.46137 - accuracy: 0.918
Training epoch 3 | loss: 0.00309 - accuracy: 0.99911
Validating epoch 3 | loss: 0.43458 - accuracy: 0.933
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.5, small_label is 0, small_prop is 0.5, balance_seed is 0
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.16261 - accuracy: 0.94478
Validating epoch 0 | loss: 0.19513 - accuracy: 0.95
94.423 s/it
Training epoch 1 | loss: 0.05167 - accuracy: 0.98678
Validating epoch 1 | loss: 0.42326 - accuracy: 0.92
Training epoch 2 | loss: 0.01508 - accuracy: 0.99711
Validating epoch 2 | loss: 0.42307 - accuracy: 0.929
Training epoch 3 | loss: 0.00705 - accuracy: 0.99833
Validating epoch 3 | loss: 0.38614 - accuracy: 0.939
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.6, small_label is 0, small_prop is 0.5, balance_seed is 0
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.17057 - accuracy: 0.94211
Validating epoch 0 | loss: 0.1852 - accuracy: 0.947
85.552 s/it
Training epoch 1 | loss: 0.04386 - accuracy: 0.988
Validating epoch 1 | loss: 0.30499 - accuracy: 0.937
Training epoch 2 | loss: 0.00961 - accuracy: 0.99789
Validating epoch 2 | loss: 0.28329 - accuracy: 0.955
Training epoch 3 | loss: 0.00361 - accuracy: 0.99922
Validating epoch 3 | loss: 0.39666 - accuracy: 0.938
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.7, small_label is 0, small_prop is 0.5, balance_seed is 0
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.16268 - accuracy: 0.94578
Validating epoch 0 | loss: 0.21576 - accuracy: 0.937
74.582 s/it
Training epoch 1 | loss: 0.03708 - accuracy: 0.99144
Validating epoch 1 | loss: 0.41922 - accuracy: 0.929
Training epoch 2 | loss: 0.00836 - accuracy: 0.99767
Validating epoch 2 | loss: 0.46885 - accuracy: 0.933
Training epoch 3 | loss: 0.00183 - accuracy: 0.99956
Validating epoch 3 | loss: 0.4165 - accuracy: 0.941
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.8, small_label is 0, small_prop is 0.5, balance_seed is 0
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.16904 - accuracy: 0.93967
Validating epoch 0 | loss: 0.25155 - accuracy: 0.938
66.673 s/it
Training epoch 1 | loss: 0.04325 - accuracy: 0.98678
Validating epoch 1 | loss: 0.34677 - accuracy: 0.933
Training epoch 2 | loss: 0.00628 - accuracy: 0.99833
Validating epoch 2 | loss: 0.33532 - accuracy: 0.948
Training epoch 3 | loss: 0.00318 - accuracy: 0.99933
Validating epoch 3 | loss: 0.3549 - accuracy: 0.948
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.9, small_label is 0, small_prop is 0.5, balance_seed is 0
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.16798 - accuracy: 0.94311
Validating epoch 0 | loss: 0.21681 - accuracy: 0.949
56.074 s/it
Training epoch 1 | loss: 0.03672 - accuracy: 0.99022
Validating epoch 1 | loss: 0.32143 - accuracy: 0.937
Training epoch 2 | loss: 0.00561 - accuracy: 0.99878
Validating epoch 2 | loss: 0.42002 - accuracy: 0.93
Training epoch 3 | loss: 0.00202 - accuracy: 0.99944
Validating epoch 3 | loss: 0.41873 - accuracy: 0.938
Model is Bert, dataset is subj, undersample is False, aug mode is None, geo is 0.5, small_label is 1, small_prop is 0.5, balance_seed is 0
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.16533 - accuracy: 0.94444
Validating epoch 0 | loss: 0.1852 - accuracy: 0.95
47.193 s/it
Training epoch 1 | loss: 0.02831 - accuracy: 0.99222
Validating epoch 1 | loss: 0.30119 - accuracy: 0.944
Training epoch 2 | loss: 0.00488 - accuracy: 0.999
Validating epoch 2 | loss: 0.35322 - accuracy: 0.951
Training epoch 3 | loss: 0.00015 - accuracy: 1.0
Validating epoch 3 | loss: 0.37093 - accuracy: 0.95
Model is Bert, dataset is subj, undersample is True, aug mode is None, geo is 0.5, small_label is 1, small_prop is 0.5, balance_seed is 0
4500 4500
4500 2250
2250 2250
Training epoch 0 | loss: 0.23898 - accuracy: 0.90578
Validating epoch 0 | loss: 0.16195 - accuracy: 0.941
24.364 s/it
Training epoch 1 | loss: 0.08073 - accuracy: 0.97622
Validating epoch 1 | loss: 0.19686 - accuracy: 0.95
Training epoch 2 | loss: 0.01901 - accuracy: 0.99556
Validating epoch 2 | loss: 0.33802 - accuracy: 0.938
Training epoch 3 | loss: 0.0035 - accuracy: 0.99933
Validating epoch 3 | loss: 0.33178 - accuracy: 0.943
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.3, small_label is 1, small_prop is 0.5, balance_seed is 0
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.16406 - accuracy: 0.93911
Validating epoch 0 | loss: 0.19505 - accuracy: 0.946
118.23 s/it
Training epoch 1 | loss: 0.05052 - accuracy: 0.98544
Validating epoch 1 | loss: 0.26637 - accuracy: 0.942
Training epoch 2 | loss: 0.01174 - accuracy: 0.99733
Validating epoch 2 | loss: 0.31058 - accuracy: 0.946
Training epoch 3 | loss: 0.00378 - accuracy: 0.99922
Validating epoch 3 | loss: 0.32715 - accuracy: 0.944
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.4, small_label is 1, small_prop is 0.5, balance_seed is 0
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.17212 - accuracy: 0.93844
Validating epoch 0 | loss: 0.17905 - accuracy: 0.94
106.974 s/it
Training epoch 1 | loss: 0.04825 - accuracy: 0.98844
Validating epoch 1 | loss: 0.36777 - accuracy: 0.928
Training epoch 2 | loss: 0.00891 - accuracy: 0.99789
Validating epoch 2 | loss: 0.36657 - accuracy: 0.938
Training epoch 3 | loss: 0.00401 - accuracy: 0.999
Validating epoch 3 | loss: 0.38196 - accuracy: 0.94
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.5, small_label is 1, small_prop is 0.5, balance_seed is 0
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.17586 - accuracy: 0.93556
Validating epoch 0 | loss: 0.22849 - accuracy: 0.926
98.93 s/it
Training epoch 1 | loss: 0.04188 - accuracy: 0.98867
Validating epoch 1 | loss: 0.28681 - accuracy: 0.944
Training epoch 2 | loss: 0.0128 - accuracy: 0.99722
Validating epoch 2 | loss: 0.35865 - accuracy: 0.937
Training epoch 3 | loss: 0.00196 - accuracy: 0.99956
Validating epoch 3 | loss: 0.35298 - accuracy: 0.948
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.6, small_label is 1, small_prop is 0.5, balance_seed is 0
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.1694 - accuracy: 0.93944
Validating epoch 0 | loss: 0.21023 - accuracy: 0.941
88.357 s/it
Training epoch 1 | loss: 0.039 - accuracy: 0.989
Validating epoch 1 | loss: 0.24268 - accuracy: 0.955
Training epoch 2 | loss: 0.01012 - accuracy: 0.99722
Validating epoch 2 | loss: 0.35541 - accuracy: 0.943
Training epoch 3 | loss: 0.00083 - accuracy: 0.99967
Validating epoch 3 | loss: 0.31963 - accuracy: 0.955
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.7, small_label is 1, small_prop is 0.5, balance_seed is 0
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.17374 - accuracy: 0.93567
Validating epoch 0 | loss: 0.17608 - accuracy: 0.943
77.255 s/it
Training epoch 1 | loss: 0.03581 - accuracy: 0.99044
Validating epoch 1 | loss: 0.27568 - accuracy: 0.946
Training epoch 2 | loss: 0.00408 - accuracy: 0.99878
Validating epoch 2 | loss: 0.4231 - accuracy: 0.938
Training epoch 3 | loss: 0.00568 - accuracy: 0.99856
Validating epoch 3 | loss: 0.36619 - accuracy: 0.948
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.8, small_label is 1, small_prop is 0.5, balance_seed is 0
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.16065 - accuracy: 0.943
Validating epoch 0 | loss: 0.19427 - accuracy: 0.945
67.403 s/it
Training epoch 1 | loss: 0.03443 - accuracy: 0.98956
Validating epoch 1 | loss: 0.30305 - accuracy: 0.948
Training epoch 2 | loss: 0.00661 - accuracy: 0.99811
Validating epoch 2 | loss: 0.32815 - accuracy: 0.948
Training epoch 3 | loss: 0.00217 - accuracy: 0.99967
Validating epoch 3 | loss: 0.34965 - accuracy: 0.946
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.9, small_label is 1, small_prop is 0.5, balance_seed is 0
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.17666 - accuracy: 0.93856
Validating epoch 0 | loss: 0.27497 - accuracy: 0.932
57.889 s/it
Training epoch 1 | loss: 0.03417 - accuracy: 0.99056
Validating epoch 1 | loss: 0.27499 - accuracy: 0.948
Training epoch 2 | loss: 0.00437 - accuracy: 0.99889
Validating epoch 2 | loss: 0.35459 - accuracy: 0.946
Training epoch 3 | loss: 0.00376 - accuracy: 0.99922
Validating epoch 3 | loss: 0.36497 - accuracy: 0.946
Model is Bert, dataset is subj, undersample is False, aug mode is None, geo is 0.5, small_label is 0, small_prop is 0.5, balance_seed is 1
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.17415 - accuracy: 0.93978
Validating epoch 0 | loss: 0.22799 - accuracy: 0.937
47.287 s/it
Training epoch 1 | loss: 0.04246 - accuracy: 0.98956
Validating epoch 1 | loss: 0.31589 - accuracy: 0.932
Training epoch 2 | loss: 0.00769 - accuracy: 0.99811
Validating epoch 2 | loss: 0.41001 - accuracy: 0.934
Training epoch 3 | loss: 0.0006 - accuracy: 0.99989
Validating epoch 3 | loss: 0.41784 - accuracy: 0.934
Model is Bert, dataset is subj, undersample is True, aug mode is None, geo is 0.5, small_label is 0, small_prop is 0.5, balance_seed is 1
4500 4500
4500 2250
2250 2250
Training epoch 0 | loss: 0.19524 - accuracy: 0.92444
Validating epoch 0 | loss: 0.16384 - accuracy: 0.946
24.302 s/it
Training epoch 1 | loss: 0.06561 - accuracy: 0.97756
Validating epoch 1 | loss: 0.21635 - accuracy: 0.95
Training epoch 2 | loss: 0.01412 - accuracy: 0.99667
Validating epoch 2 | loss: 0.27836 - accuracy: 0.952
Training epoch 3 | loss: 0.00241 - accuracy: 0.99956
Validating epoch 3 | loss: 0.30345 - accuracy: 0.949
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.3, small_label is 0, small_prop is 0.5, balance_seed is 1
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.15038 - accuracy: 0.95011
Validating epoch 0 | loss: 0.28443 - accuracy: 0.922
114.103 s/it
Training epoch 1 | loss: 0.03795 - accuracy: 0.98889
Validating epoch 1 | loss: 0.4894 - accuracy: 0.918
Training epoch 2 | loss: 0.01052 - accuracy: 0.99767
Validating epoch 2 | loss: 0.57242 - accuracy: 0.916
Training epoch 3 | loss: 0.00164 - accuracy: 0.99967
Validating epoch 3 | loss: 0.50406 - accuracy: 0.929
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.4, small_label is 0, small_prop is 0.5, balance_seed is 1
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.15754 - accuracy: 0.94389
Validating epoch 0 | loss: 0.45875 - accuracy: 0.887
103.675 s/it
Training epoch 1 | loss: 0.04347 - accuracy: 0.98656
Validating epoch 1 | loss: 0.34449 - accuracy: 0.926
Training epoch 2 | loss: 0.00575 - accuracy: 0.99822
Validating epoch 2 | loss: 0.40745 - accuracy: 0.943
Training epoch 3 | loss: 0.0034 - accuracy: 0.99933
Validating epoch 3 | loss: 0.41658 - accuracy: 0.943
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.5, small_label is 0, small_prop is 0.5, balance_seed is 1
4500 4500
4500 2250
4500 4500
Training epoch 0 | loss: 0.16069 - accuracy: 0.94044
Validating epoch 0 | loss: 0.21682 - accuracy: 0.942
94.983 s/it
Training epoch 1 | loss: 0.03785 - accuracy: 0.99011
Validating epoch 1 | loss: 0.3293 - accuracy: 0.934
Training epoch 2 | loss: 0.01042 - accuracy: 0.99744
Validating epoch 2 | loss: 0.45463 - accuracy: 0.93
Training epoch 3 | loss: 0.00331 - accuracy: 0.999
Validating epoch 3 | loss: 0.43662 - accuracy: 0.936
Model is Bert, dataset is subj, undersample is False, aug mode is synonym, geo is 0.6, small_label is 0, small_prop is 0.5, balance_seed is 1
4500 4500
4500 2250
4500 4500
Traceback (most recent call last):
  File "experiments/bert_syn_subj.py", line 41, in <module>
    experiment(balance_seed)
  File "experiments/bert_syn_subj.py", line 37, in experiment
    agent.run()
  File "/u6/dltammin/thesis/agents/bert.py", line 89, in run
    self.train()
  File "/u6/dltammin/thesis/agents/bert.py", line 108, in train
    self.train_one_epoch()
  File "/u6/dltammin/thesis/agents/bert.py", line 131, in train_one_epoch
    x, attention_mask=attention_mask, labels=y)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 1161, in forward
    inputs_embeds=inputs_embeds,
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 811, in forward
    encoder_attention_mask=encoder_extended_attention_mask,
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 422, in forward
    hidden_states, attention_mask, head_mask[i], encoder_hidden_states, encoder_attention_mask
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 394, in forward
    intermediate_output = self.intermediate(attention_output)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 347, in forward
    hidden_states = self.intermediate_act_fn(hidden_states)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 134, in gelu
    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 1; 22.38 GiB total capacity; 20.23 GiB already allocated; 8.06 MiB free; 1.52 GiB cached)
