  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:24<04:12, 84.03s/it] 50%|█████     | 2/4 [02:46<02:46, 83.45s/it] 75%|███████▌  | 3/4 [04:08<01:22, 82.98s/it]100%|██████████| 4/4 [05:28<00:00, 82.31s/it]100%|██████████| 4/4 [05:28<00:00, 82.19s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:10<00:30, 10.13s/it] 50%|█████     | 2/4 [00:20<00:20, 10.15s/it] 75%|███████▌  | 3/4 [00:30<00:10, 10.10s/it]100%|██████████| 4/4 [00:40<00:00, 10.03s/it]100%|██████████| 4/4 [00:40<00:00, 10.04s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [02:01<06:03, 121.24s/it] 50%|█████     | 2/4 [03:57<03:59, 119.77s/it] 75%|███████▌  | 3/4 [05:51<01:58, 118.01s/it]100%|██████████| 4/4 [07:45<00:00, 116.95s/it]100%|██████████| 4/4 [07:45<00:00, 116.49s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:49<05:28, 109.40s/it] 50%|█████     | 2/4 [03:37<03:38, 109.01s/it] 75%|███████▌  | 3/4 [05:24<01:48, 108.41s/it]100%|██████████| 4/4 [07:11<00:00, 107.99s/it]100%|██████████| 4/4 [07:11<00:00, 107.88s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:44<05:12, 104.12s/it] 50%|█████     | 2/4 [03:26<03:27, 103.61s/it] 75%|███████▌  | 3/4 [05:08<01:43, 103.13s/it]100%|██████████| 4/4 [06:49<00:00, 102.53s/it]100%|██████████| 4/4 [06:49<00:00, 102.42s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:36<04:49, 96.51s/it] 50%|█████     | 2/4 [03:11<03:12, 96.07s/it] 75%|███████▌  | 3/4 [04:45<01:35, 95.55s/it]100%|██████████| 4/4 [06:20<00:00, 95.20s/it]100%|██████████| 4/4 [06:20<00:00, 95.07s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:30<04:30, 90.00s/it] 50%|█████     | 2/4 [02:58<02:59, 89.53s/it] 75%|███████▌  | 3/4 [04:28<01:29, 89.82s/it]100%|██████████| 4/4 [05:56<00:00, 89.02s/it]100%|██████████| 4/4 [05:56<00:00, 89.02s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:22<04:08, 82.94s/it] 50%|█████     | 2/4 [02:44<02:44, 82.40s/it] 75%|███████▌  | 3/4 [04:05<01:21, 81.98s/it]100%|██████████| 4/4 [05:25<00:00, 81.58s/it]100%|██████████| 4/4 [05:25<00:00, 81.43s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:10<00:32, 10.77s/it] 50%|█████     | 2/4 [00:21<00:21, 10.74s/it] 75%|███████▌  | 3/4 [00:32<00:10, 10.70s/it]100%|██████████| 4/4 [00:42<00:00, 10.64s/it]100%|██████████| 4/4 [00:42<00:00, 10.64s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [02:02<06:06, 122.12s/it] 50%|█████     | 2/4 [04:01<04:02, 121.33s/it] 75%|███████▌  | 3/4 [05:58<01:59, 119.92s/it]100%|██████████| 4/4 [07:55<00:00, 119.19s/it]100%|██████████| 4/4 [07:55<00:00, 118.93s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:52<05:37, 112.64s/it] 50%|█████     | 2/4 [03:43<03:44, 112.06s/it] 75%|███████▌  | 3/4 [05:32<01:51, 111.29s/it]100%|██████████| 4/4 [07:21<00:00, 110.53s/it]100%|██████████| 4/4 [07:21<00:00, 110.40s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:45<05:16, 105.56s/it] 50%|█████     | 2/4 [03:29<03:30, 105.09s/it] 75%|███████▌  | 3/4 [05:19<01:46, 106.52s/it]100%|██████████| 4/4 [07:04<00:00, 106.03s/it]100%|██████████| 4/4 [07:04<00:00, 106.08s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:37<04:53, 97.70s/it] 50%|█████     | 2/4 [03:11<03:13, 96.55s/it] 75%|███████▌  | 3/4 [04:46<01:35, 95.99s/it]100%|██████████| 4/4 [06:20<00:00, 95.53s/it]100%|██████████| 4/4 [06:20<00:00, 95.17s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [01:29<04:27, 89.02s/it] 50%|█████     | 2/4 [02:56<02:56, 88.44s/it] 75%|███████▌  | 3/4 [04:23<01:28, 88.19s/it]100%|██████████| 4/4 [05:52<00:00, 88.23s/it]100%|██████████| 4/4 [05:52<00:00, 88.01s/it]
  0%|          | 0/4 [00:00<?, ?it/s]  0%|          | 0/4 [00:00<?, ?it/s]
Model is Bert, dataset is sst, undersample is False, aug mode is None, geo is 0.5, small_label is 0, small_prop is 0.1, balance_seed is 0
3610 3310
3610 331
3610 3310
Training epoch 0 | loss: 0.28333 - accuracy: 0.87327
Validating epoch 0 | loss: 1.99333 - accuracy: 0.68922
84.031 s/it
Training epoch 1 | loss: 0.03839 - accuracy: 0.99277
Validating epoch 1 | loss: 2.11836 - accuracy: 0.74197
Training epoch 2 | loss: 0.01493 - accuracy: 0.99754
Validating epoch 2 | loss: 2.26386 - accuracy: 0.73509
Training epoch 3 | loss: 0.00205 - accuracy: 0.99971
Validating epoch 3 | loss: 2.48869 - accuracy: 0.72248
Model is Bert, dataset is sst, undersample is True, aug mode is None, geo is 0.5, small_label is 0, small_prop is 0.1, balance_seed is 0
3610 3310
3610 331
331 331
Training epoch 0 | loss: 0.63135 - accuracy: 0.64199
Validating epoch 0 | loss: 0.4416 - accuracy: 0.82798
10.126 s/it
Training epoch 1 | loss: 0.31691 - accuracy: 0.88671
Validating epoch 1 | loss: 0.48109 - accuracy: 0.82569
Training epoch 2 | loss: 0.15318 - accuracy: 0.94713
Validating epoch 2 | loss: 0.64116 - accuracy: 0.8406
Training epoch 3 | loss: 0.06604 - accuracy: 0.9864
Validating epoch 3 | loss: 0.69067 - accuracy: 0.84289
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.5, small_label is 0, small_prop is 0.1, balance_seed is 0
3610 3310
3610 331
3610 3310
Training epoch 0 | loss: 0.3261 - accuracy: 0.8565
Validating epoch 0 | loss: 1.49858 - accuracy: 0.74427
121.236 s/it
Training epoch 1 | loss: 0.05532 - accuracy: 0.98772
Validating epoch 1 | loss: 1.50998 - accuracy: 0.78899
Training epoch 2 | loss: 0.01371 - accuracy: 0.99754
Validating epoch 2 | loss: 2.31002 - accuracy: 0.71674
Training epoch 3 | loss: 0.00328 - accuracy: 0.99928
Validating epoch 3 | loss: 2.44385 - accuracy: 0.7156
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.6, small_label is 0, small_prop is 0.1, balance_seed is 0
3610 3310
3610 331
3610 3310
Training epoch 0 | loss: 0.33153 - accuracy: 0.85621
Validating epoch 0 | loss: 1.21244 - accuracy: 0.77408
109.405 s/it
Training epoch 1 | loss: 0.05736 - accuracy: 0.98887
Validating epoch 1 | loss: 1.64453 - accuracy: 0.77179
Training epoch 2 | loss: 0.01342 - accuracy: 0.99769
Validating epoch 2 | loss: 2.13342 - accuracy: 0.75
Training epoch 3 | loss: 0.01065 - accuracy: 0.99769
Validating epoch 3 | loss: 2.23101 - accuracy: 0.74771
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.7, small_label is 0, small_prop is 0.1, balance_seed is 0
3610 3310
3610 331
3610 3310
Training epoch 0 | loss: 0.32447 - accuracy: 0.86633
Validating epoch 0 | loss: 1.3917 - accuracy: 0.76835
104.122 s/it
Training epoch 1 | loss: 0.04789 - accuracy: 0.98988
Validating epoch 1 | loss: 2.58845 - accuracy: 0.67431
Training epoch 2 | loss: 0.01761 - accuracy: 0.99653
Validating epoch 2 | loss: 2.34526 - accuracy: 0.7156
Training epoch 3 | loss: 0.01072 - accuracy: 0.99798
Validating epoch 3 | loss: 2.44558 - accuracy: 0.71101
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.8, small_label is 0, small_prop is 0.1, balance_seed is 0
3610 3310
3610 331
3610 3310
Training epoch 0 | loss: 0.31889 - accuracy: 0.86214
Validating epoch 0 | loss: 1.26762 - accuracy: 0.74656
96.513 s/it
Training epoch 1 | loss: 0.04591 - accuracy: 0.99046
Validating epoch 1 | loss: 2.26239 - accuracy: 0.70757
Training epoch 2 | loss: 0.01489 - accuracy: 0.9974
Validating epoch 2 | loss: 1.88141 - accuracy: 0.76032
Training epoch 3 | loss: 0.00743 - accuracy: 0.99841
Validating epoch 3 | loss: 2.0323 - accuracy: 0.75459
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.9, small_label is 0, small_prop is 0.1, balance_seed is 0
3610 3310
3610 331
3610 3310
Training epoch 0 | loss: 0.29905 - accuracy: 0.86777
Validating epoch 0 | loss: 1.21746 - accuracy: 0.80161
90.003 s/it
Training epoch 1 | loss: 0.04185 - accuracy: 0.99249
Validating epoch 1 | loss: 2.24506 - accuracy: 0.70872
Training epoch 2 | loss: 0.016 - accuracy: 0.99697
Validating epoch 2 | loss: 1.83197 - accuracy: 0.76835
Training epoch 3 | loss: 0.00685 - accuracy: 0.99884
Validating epoch 3 | loss: 2.15116 - accuracy: 0.73968
Model is Bert, dataset is sst, undersample is False, aug mode is None, geo is 0.5, small_label is 1, small_prop is 0.1, balance_seed is 0
3310 3610
3310 361
3310 3610
Training epoch 0 | loss: 0.30877 - accuracy: 0.86301
Validating epoch 0 | loss: 0.84586 - accuracy: 0.85436
82.939 s/it
Training epoch 1 | loss: 0.02965 - accuracy: 0.99422
Validating epoch 1 | loss: 1.81282 - accuracy: 0.77179
Training epoch 2 | loss: 0.00524 - accuracy: 0.99855
Validating epoch 2 | loss: 1.97451 - accuracy: 0.77523
Training epoch 3 | loss: 0.00504 - accuracy: 0.99942
Validating epoch 3 | loss: 1.86425 - accuracy: 0.79358
Model is Bert, dataset is sst, undersample is True, aug mode is None, geo is 0.5, small_label is 1, small_prop is 0.1, balance_seed is 0
3310 3610
3310 361
361 361
Training epoch 0 | loss: 0.61371 - accuracy: 0.6385
Validating epoch 0 | loss: 0.43633 - accuracy: 0.81537
10.766 s/it
Training epoch 1 | loss: 0.37083 - accuracy: 0.85596
Validating epoch 1 | loss: 0.45989 - accuracy: 0.84289
Training epoch 2 | loss: 0.19806 - accuracy: 0.93767
Validating epoch 2 | loss: 0.60368 - accuracy: 0.8383
Training epoch 3 | loss: 0.09919 - accuracy: 0.97091
Validating epoch 3 | loss: 0.65018 - accuracy: 0.8383
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.5, small_label is 1, small_prop is 0.1, balance_seed is 0
3310 3610
3310 361
3310 3610
Training epoch 0 | loss: 0.35201 - accuracy: 0.84523
Validating epoch 0 | loss: 0.91839 - accuracy: 0.81766
122.116 s/it
Training epoch 1 | loss: 0.06597 - accuracy: 0.98627
Validating epoch 1 | loss: 1.35571 - accuracy: 0.78899
Training epoch 2 | loss: 0.0212 - accuracy: 0.99595
Validating epoch 2 | loss: 1.47188 - accuracy: 0.80275
Training epoch 3 | loss: 0.01142 - accuracy: 0.99754
Validating epoch 3 | loss: 1.54097 - accuracy: 0.80046
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.6, small_label is 1, small_prop is 0.1, balance_seed is 0
3310 3610
3310 361
3310 3610
Training epoch 0 | loss: 0.32996 - accuracy: 0.85376
Validating epoch 0 | loss: 0.90646 - accuracy: 0.83142
112.638 s/it
Training epoch 1 | loss: 0.05161 - accuracy: 0.98931
Validating epoch 1 | loss: 1.67327 - accuracy: 0.77982
Training epoch 2 | loss: 0.01764 - accuracy: 0.99682
Validating epoch 2 | loss: 1.60532 - accuracy: 0.80275
Training epoch 3 | loss: 0.00968 - accuracy: 0.99827
Validating epoch 3 | loss: 1.65426 - accuracy: 0.79817
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.7, small_label is 1, small_prop is 0.1, balance_seed is 0
3310 3610
3310 361
3310 3610
Training epoch 0 | loss: 0.31159 - accuracy: 0.86936
Validating epoch 0 | loss: 1.08651 - accuracy: 0.81422
105.558 s/it
Training epoch 1 | loss: 0.05456 - accuracy: 0.98887
Validating epoch 1 | loss: 1.43016 - accuracy: 0.8039
Training epoch 2 | loss: 0.01596 - accuracy: 0.99697
Validating epoch 2 | loss: 1.3057 - accuracy: 0.84518
Training epoch 3 | loss: 0.00889 - accuracy: 0.99841
Validating epoch 3 | loss: 1.55269 - accuracy: 0.81995
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.8, small_label is 1, small_prop is 0.1, balance_seed is 0
3310 3610
3310 361
3310 3610
Training epoch 0 | loss: 0.31194 - accuracy: 0.87168
Validating epoch 0 | loss: 1.04536 - accuracy: 0.81995
97.703 s/it
Training epoch 1 | loss: 0.05144 - accuracy: 0.98945
Validating epoch 1 | loss: 1.74973 - accuracy: 0.77179
Training epoch 2 | loss: 0.01414 - accuracy: 0.9974
Validating epoch 2 | loss: 1.43717 - accuracy: 0.83028
Training epoch 3 | loss: 0.00843 - accuracy: 0.99798
Validating epoch 3 | loss: 1.68786 - accuracy: 0.80275
Model is Bert, dataset is sst, undersample is False, aug mode is synonym, geo is 0.9, small_label is 1, small_prop is 0.1, balance_seed is 0
3310 3610
3310 361
3310 3610
Training epoch 0 | loss: 0.31507 - accuracy: 0.85997
Validating epoch 0 | loss: 1.45229 - accuracy: 0.75573
89.022 s/it
Training epoch 1 | loss: 0.04693 - accuracy: 0.99075
Validating epoch 1 | loss: 1.47517 - accuracy: 0.80161
Training epoch 2 | loss: 0.01936 - accuracy: 0.99682
Validating epoch 2 | loss: 1.63913 - accuracy: 0.78326
Training epoch 3 | loss: 0.00492 - accuracy: 0.99928
Validating epoch 3 | loss: 1.69304 - accuracy: 0.79128
Model is Bert, dataset is sst, undersample is False, aug mode is None, geo is 0.5, small_label is 0, small_prop is 0.2, balance_seed is 0
3610 3310
3610 662
3610 3310
Traceback (most recent call last):
  File "experiments/bal_bert_syn_sst.py", line 46, in <module>
    experiment(balance_seed)
  File "experiments/bal_bert_syn_sst.py", line 35, in experiment
    agent.run()
  File "/u6/dltammin/thesis/agents/bert.py", line 86, in run
    self.train()
  File "/u6/dltammin/thesis/agents/bert.py", line 103, in train
    self.train_one_epoch()
  File "/u6/dltammin/thesis/agents/bert.py", line 126, in train_one_epoch
    x, attention_mask=attention_mask, labels=y)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 1161, in forward
    inputs_embeds=inputs_embeds,
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 811, in forward
    encoder_attention_mask=encoder_extended_attention_mask,
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 422, in forward
    hidden_states, attention_mask, head_mask[i], encoder_hidden_states, encoder_attention_mask
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 394, in forward
    intermediate_output = self.intermediate(attention_output)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 347, in forward
    hidden_states = self.intermediate_act_fn(hidden_states)
  File "/u6/dltammin/thesis/env/lib/python3.6/site-packages/transformers/modeling_bert.py", line 134, in gelu
    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 22.38 GiB total capacity; 20.23 GiB already allocated; 10.06 MiB free; 1.53 GiB cached)
